name: Deploy frontend to S3 + CloudFront

on:
  workflow_dispatch: {}
  push:
    branches: [main]
    # Run only when frontend/ or this workflow changes
    paths:
      - "frontend/**"
      - ".github/workflows/deploy-frontend.yml"

permissions:
  id-token: write # Required for GitHub OIDC -> AWS STS
  contents: read

env:
  AWS_REGION: us-east-1
  S3_BUCKET: aws-portfolio-liyu
  CF_DISTRIBUTION_ID: EOJPSKY8NNVO2
  AWS_ACCOUNT_ID: "277375108569"

jobs:
  deploy:
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: frontend # All shell commands run in frontend/

    steps:
      # 1) Get your code
      - name: Checkout
        uses: actions/checkout@v4

      # 2) Assume AWS role via OIDC (no long-lived keys)
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v5
        with:
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: arn:aws:iam::${{ env.AWS_ACCOUNT_ID }}:role/GitHubS3DeployRole

      # Print GitHub context to match your trust policy strings
      - name: Print GitHub context (for trust policy)
        run: |
          echo "github.repository=${{ github.repository }}"
          echo "github.ref=${{ github.ref }}"
          echo "github.workflow_ref=${{ github.workflow_ref }}"
          echo "github.repository_owner=${{ github.repository_owner }}"

      # --- Smoke tests: verify identity, S3, CloudFront ---
      - name: Who am I?
        run: aws sts get-caller-identity

      - name: S3 smoke test (list bucket)
        run: aws s3 ls s3://$S3_BUCKET/ || true

      - name: CloudFront smoke test (one fake path)
        run: |
          aws cloudfront create-invalidation \
            --distribution-id $CF_DISTRIBUTION_ID \
            --paths "/__smoketest_$(date +%s).txt"
      # --- End smoke tests ---
      # 3) Upload non-HTML assets with long cache (30 days)
      #    Put your assets under css/, js/, img/, images/, fonts/, assets/ ...
      - name: Upload assets with long cache
        run: |
          aws s3 cp . s3://$S3_BUCKET/ \
            --recursive \
            --exclude ".DS_Store" \
            --exclude "*.html" \
            --cache-control "public, max-age=2592000"  # 30 days

      # 4) Upload HTML with no-cache (always fetch fresh shell)
      - name: Upload HTML with no-cache
        run: |
          find . -maxdepth 1 -type f -name "*.html" -print0 | while IFS= read -r -d '' f; do
            key="${f#./}"
            aws s3 cp "$f" "s3://$S3_BUCKET/$key" --cache-control "no-cache"
          done

      # 5) Mirror deletion (remove files in S3 that no longer exist locally)
      - name: Prune removed files
        run: |
          aws s3 sync . s3://$S3_BUCKET --delete \
            --exclude ".DS_Store"

      # 6) Invalidate only HTML (fast & free-tier friendly)
      - name: Invalidate CloudFront (HTML only)
        run: |
          HTML_PATHS=$(find . -maxdepth 1 -type f -name "*.html" -printf ' "/%f"')
          if [ -z "$HTML_PATHS" ]; then
            HTML_PATHS='"/index.html"'
          fi
          aws cloudfront create-invalidation \
            --distribution-id $CF_DISTRIBUTION_ID \
            --paths $HTML_PATHS

      - name: Summary
        run: |
          echo "Deployed to s3://$S3_BUCKET (region: $AWS_REGION)"
          echo "CloudFront Distribution: $CF_DISTRIBUTION_ID"
